#!/bin/bash
# MCP Grid Setup Script - Sequential Thinking for Ollama
# Sets up the Sequential Thinking MCP server for use with Ollama

echo "ü¶ô INITIALIZING SEQUENTIAL THINKING FOR OLLAMA..."
echo ""

# Check if Node.js is installed
if command -v node &> /dev/null; then
    NODE_VERSION=$(node --version)
    echo "‚úì Node.js detected: $NODE_VERSION"
else
    echo "‚ùå Node.js not found. Please install Node.js first."
    echo "   Download from: https://nodejs.org/"
    echo "   Or use your system package manager"
    exit 1
fi

# Check if npm is available
if command -v npm &> /dev/null; then
    NPM_VERSION=$(npm --version)
    echo "‚úì NPM detected: $NPM_VERSION"
else
    echo "‚ùå NPM not found. Please install NPM first."
    exit 1
fi

# Check if Ollama is installed
if command -v ollama &> /dev/null; then
    echo "‚úì Ollama detected"
else
    echo "‚ö†Ô∏è  Ollama not found. Install Ollama first:"
    echo "   Visit: https://ollama.ai/"
    echo "   Or use: curl -fsSL https://ollama.ai/install.sh | sh"
    echo ""
    echo "   Continuing with MCP server installation..."
fi

echo ""
echo "üöÄ INSTALLING SEQUENTIAL THINKING MCP SERVER..."

# Install the Sequential Thinking MCP server
if npm install -g @modelcontextprotocol/server-sequential-thinking; then
    echo "‚úì Sequential Thinking MCP server installed successfully"
else
    echo "‚ùå Failed to install Sequential Thinking MCP server"
    echo "   Trying alternative installation method..."

    # Alternative: local installation
    if mkdir -p mcp-servers/shared/sequential-thinking && \
       cd mcp-servers/shared/sequential-thinking && \
       npm init -y && \
       npm install @modelcontextprotocol/server-sequential-thinking && \
       cd ../../..; then
        echo "‚úì Sequential Thinking MCP server installed locally"
    else
        echo "‚ùå Installation failed. Please check your network connection and try again."
        exit 1
    fi
fi

echo ""
echo "üéØ TESTING INSTALLATION..."

# Test if the server can be started
if npx @modelcontextprotocol/server-sequential-thinking --help &> /dev/null; then
    echo "‚úì Sequential Thinking server responds correctly"
else
    echo "‚ö†Ô∏è  Unable to test server - this may be normal"
fi

echo ""
echo "ü¶ô OLLAMA + SEQUENTIAL THINKING SETUP COMPLETE!"
echo ""
echo "üîß INTEGRATION OPTIONS:"
echo ""
echo "1. üì± Use with Open WebUI:"
echo "   ‚Ä¢ Open WebUI supports MCP server integration"
echo "   ‚Ä¢ Configure Open WebUI to connect to MCP servers"
echo "   ‚Ä¢ Enhanced reasoning will supplement Ollama responses"
echo ""
echo "2. üîó Custom Application Integration:"
echo "   ‚Ä¢ Start MCP server: npx @modelcontextprotocol/server-sequential-thinking"
echo "   ‚Ä¢ Build bridge between Ollama API and MCP protocol"
echo "   ‚Ä¢ Use tools like LangChain for workflow integration"
echo ""
echo "3. üõ†Ô∏è Manual Usage:"
echo "   ‚Ä¢ Run MCP server in one terminal"
echo "   ‚Ä¢ Use Ollama in another terminal"
echo "   ‚Ä¢ Combine outputs for enhanced reasoning"
echo ""
echo "üìñ EXAMPLE USAGE:"
echo "   Ask your Ollama-powered application:"
echo "   'Use sequential thinking to analyze this problem step by step'"
echo ""
echo "Status: READY FOR OLLAMA INTEGRATION ü¶ô‚ö°"
